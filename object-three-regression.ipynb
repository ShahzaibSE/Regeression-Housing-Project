{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Prepare dataset & create baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
       "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
       "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
       "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
       "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
       "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
       "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "501  391.99  9.67  22.4  \n",
       "502  396.90  9.08  20.6  \n",
       "503  396.90  5.64  23.9  \n",
       "504  393.45  6.48  22.0  \n",
       "505  396.90  7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset = pd.read_csv('./housing.csv', header=None, delim_whitespace=True)\n",
    "house_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_dataset.iloc[:,0:13]\n",
    "Y = house_dataset.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -38.73 (28.50) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Modeling The Standardized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -21.74 (27.57) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 - use a Sigmoid or similar activation function on the output layer to narrow output predictions to the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -549.12 (273.00) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=new_baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Tune The Neural Network Topology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 - Evaluate a Deeper Network Topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(6,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -21.52 (25.84) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2. Evaluate a Wider Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(20,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -21.42 (21.47) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Really Scaling up: developing a model that overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(30,activation='relu'))\n",
    "    model.add(Dense(30,activation='relu'))\n",
    "    model.add(Dense(20,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -35.57 (31.48) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=overfit_model, epochs=150, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Result: Standardized: -20.45 (25.99) MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Rewriting the code using the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functional_api():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 10082.18% (36258.73%)\n"
     ]
    }
   ],
   "source": [
    "model = functional_api()\n",
    "history = model.fit(X,Y,epochs=50, batch_size=5, verbose=False)\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['loss']\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (np.mean(acc_values)*100, np.std(acc_values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Rewriting the code by doing Model Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense1 = Dense(13,activation='relu')\n",
    "        self.dense2 = Dense(13,activation='relu')\n",
    "        self.dense3 = Dense(1)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "def subclass_model():\n",
    "    inputs = tf.keras.Input(shape=(13,))\n",
    "    mymodel = MyModel()\n",
    "    outputs = mymodel.call(inputs)\n",
    "    # Keras Model.\n",
    "    model = tf.keras.Model(inputs,outputs)\n",
    "    # Compile.\n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 506 samples\n",
      "Epoch 1/50\n",
      "506/506 [==============================] - 1s 3ms/sample - loss: 178.8052 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "506/506 [==============================] - 0s 701us/sample - loss: 70.5227 - acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "506/506 [==============================] - 0s 704us/sample - loss: 64.9343 - acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "506/506 [==============================] - 0s 723us/sample - loss: 64.4175 - acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "506/506 [==============================] - 0s 718us/sample - loss: 54.6050 - acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "506/506 [==============================] - 0s 721us/sample - loss: 55.0880 - acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "506/506 [==============================] - 0s 694us/sample - loss: 48.2680 - acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "506/506 [==============================] - 0s 711us/sample - loss: 48.5837 - acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "506/506 [==============================] - 0s 707us/sample - loss: 49.3413 - acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "506/506 [==============================] - 0s 693us/sample - loss: 47.8172 - acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "506/506 [==============================] - 0s 696us/sample - loss: 44.8721 - acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "506/506 [==============================] - 0s 702us/sample - loss: 46.4440 - acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "506/506 [==============================] - 0s 738us/sample - loss: 39.9407 - acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "506/506 [==============================] - 0s 727us/sample - loss: 45.4936 - acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "506/506 [==============================] - 0s 688us/sample - loss: 40.8621 - acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "506/506 [==============================] - 0s 690us/sample - loss: 43.9767 - acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "506/506 [==============================] - 0s 744us/sample - loss: 40.0276 - acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "506/506 [==============================] - 0s 684us/sample - loss: 38.8802 - acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "506/506 [==============================] - 0s 705us/sample - loss: 49.1352 - acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "506/506 [==============================] - 0s 698us/sample - loss: 40.5149 - acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "506/506 [==============================] - 0s 684us/sample - loss: 48.5475 - acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "506/506 [==============================] - 0s 687us/sample - loss: 37.9343 - acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "506/506 [==============================] - 0s 676us/sample - loss: 42.1233 - acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "506/506 [==============================] - 0s 716us/sample - loss: 44.2780 - acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "506/506 [==============================] - 0s 726us/sample - loss: 38.0191 - acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "506/506 [==============================] - 0s 746us/sample - loss: 43.7889 - acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "506/506 [==============================] - 0s 691us/sample - loss: 38.8551 - acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "506/506 [==============================] - 0s 961us/sample - loss: 41.9542 - acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "506/506 [==============================] - 0s 789us/sample - loss: 38.3024 - acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "506/506 [==============================] - 0s 679us/sample - loss: 39.6326 - acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "506/506 [==============================] - 0s 669us/sample - loss: 36.1319 - acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "506/506 [==============================] - 0s 662us/sample - loss: 39.6621 - acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "506/506 [==============================] - 0s 680us/sample - loss: 35.4323 - acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "506/506 [==============================] - 0s 689us/sample - loss: 43.4450 - acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "506/506 [==============================] - 0s 696us/sample - loss: 39.3167 - acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "506/506 [==============================] - 0s 680us/sample - loss: 41.3394 - acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "506/506 [==============================] - 0s 680us/sample - loss: 36.9843 - acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "506/506 [==============================] - 0s 673us/sample - loss: 36.7486 - acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "506/506 [==============================] - 0s 677us/sample - loss: 34.2445 - acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "506/506 [==============================] - 0s 694us/sample - loss: 33.6720 - acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "506/506 [==============================] - 0s 668us/sample - loss: 46.1040 - acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "506/506 [==============================] - 0s 693us/sample - loss: 35.6683 - acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "506/506 [==============================] - 0s 748us/sample - loss: 39.0646 - acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "506/506 [==============================] - 0s 703us/sample - loss: 36.3030 - acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "506/506 [==============================] - 0s 719us/sample - loss: 36.5213 - acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "506/506 [==============================] - 0s 788us/sample - loss: 33.5992 - acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "506/506 [==============================] - 0s 735us/sample - loss: 33.6512 - acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "506/506 [==============================] - 0s 689us/sample - loss: 30.7160 - acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "506/506 [==============================] - 0s 693us/sample - loss: 33.2209 - acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "506/506 [==============================] - 0s 697us/sample - loss: 42.5620 - acc: 0.0000e+00\n",
      "Result: 4540.71% (2071.48%)\n"
     ]
    }
   ],
   "source": [
    "mymodel = subclass_model()\n",
    "history = mymodel.fit(X,Y,epochs=50, batch_size=5, verbose=True)\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['loss']\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (np.mean(acc_values)*100, np.std(acc_values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Rewriting the code without using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n",
      "processing fold # 4\n",
      "processing fold # 5\n",
      "processing fold # 6\n",
      "processing fold # 7\n",
      "processing fold # 8\n",
      "processing fold # 9\n"
     ]
    }
   ],
   "source": [
    "k=10\n",
    "num_val_samples = len(X) // k\n",
    "num_epochs = 50\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = Y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "#     print(val_data,val_targets)\n",
    "#     partial_train_data =np.concatenate([X[:i * num_val_samples],X[(i + 1) * num_val_samples:]],axis=0)\n",
    "#     partial_train_targets =np.concatenate([Y[:i * num_val_samples],Y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = baseline_model()\n",
    "    model.fit(val_data, val_targets,epochs=num_epochs, batch_size=5, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Results: 0.0%,0.0%.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"K-Fold Results: {str(np.mean(all_scores)*100)}%,{str(np.std(all_scores)*100)}%.\")\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
